{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb7qyhNL1yWt"
      },
      "source": [
        "# Image Classification with TensorFlow Lite Model Maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcLF2PKkSbV3"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "To run this example, we first need to install several required packages, including Model Maker package that in GitHub [repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cv3K3oaksJv"
      },
      "outputs": [],
      "source": [
        "!sudo apt -y install libportaudio2\n",
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx1HGRoFQ54j"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtxiUeZEiXpt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKRaYHABpob5"
      },
      "source": [
        "## Simple End-to-End Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ahtcO86tZBL"
      },
      "source": [
        "Step 1.   Load input data specific to an on-device ML app. Split it into training data and testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3jz5x0JoskPv"
      },
      "outputs": [],
      "source": [
        "os.mkdir(\"database\")\n",
        "!unzip database.zip -d database/\n",
        "image_path=\"database\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lANoNS_gtdH1"
      },
      "outputs": [],
      "source": [
        "data = DataLoader.from_folder(image_path)\n",
        "train_data, test_data = data.split(0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_9IWyIztuRF"
      },
      "source": [
        "Step 2. Customize the TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRXMZbrwtyRD"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(train_data, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxU2fDr-t2Ya"
      },
      "source": [
        "Step 3. Evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQr02VxJt6Cs"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVZw9zU8t84y"
      },
      "source": [
        "Step 4.  Export to TensorFlow Lite model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb-eIzfluCoa"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='model.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5. Export to labels.txt"
      ],
      "metadata": {
        "id": "HQbyGCSr9g9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.export(export_dir='.', export_format=ExportFormat.LABEL)"
      ],
      "metadata": {
        "id": "h8Q0ecWd8BCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**---------------------------------------**"
      ],
      "metadata": {
        "id": "77T6unbH_dl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing TF Lite Model"
      ],
      "metadata": {
        "id": "hvyenNiD_qQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "id": "mhpXV4iMArCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.lite as tflite\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uRXpaE-mAEP9"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tflite.Interpreter(model_path='model.tflite')\n",
        "\n",
        "with open(\"labels.txt\", 'r') as f:\n",
        "    labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "#allocate the tensors\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "metadata": {
        "id": "H-GxK5rGAGj2"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reader(image_path):\n",
        "    #image name here\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img,(224, 224))\n",
        "    #Preprocess the image to required size and castinput_shape = input_details[0]['shape']\n",
        "    input_tensor= np.array(np.expand_dims(img,0))\n",
        "    input_tensor=input_tensor.astype('uint8') #uint8 for colab trained, float32 for normal\n",
        "\n",
        "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "    interpreter.set_tensor(input_index, input_tensor)\n",
        "    interpreter.invoke()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    pred = np.squeeze(output_data)\n",
        "\n",
        "    highest_pred_loc = np.argmax(pred)\n",
        "    object_name = labels[highest_pred_loc-1]\n",
        "    print(f\"It's a {object_name}.\")"
      ],
      "metadata": {
        "id": "f6EQ9fdmBMDz"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reader(\"test.jpg\")"
      ],
      "metadata": {
        "id": "W75eQ41fBN_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Model Maker Image Classification Tutorial adlı not defterinin kopyası",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}